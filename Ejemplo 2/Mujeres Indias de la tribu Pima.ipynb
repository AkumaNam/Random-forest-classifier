{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfcc2fa9",
   "metadata": {},
   "source": [
    "## Pima Indian Woman Diabetes\n",
    "\n",
    "Tenemos un modelo que tiene la informacion de las mujeres indias de Pima, con esta informacion y una prueba de diabetes podemos entrenar nuestro modelo para que prediga si la mujer tiene o no diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a9388b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e04533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/09 19:54:15 WARN Utils: Your hostname, flores-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "21/12/09 19:54:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/flores/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/12/09 19:54:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('rfcExample').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1eda0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('pima-indians-diabetes.data.csv', inferSchema=True, header=True).toDF(\"embarazo_meses\",\"concentracion_glucosa\",\"presion_arterial\",\"espesor_triceps\",\"insulina\",\"masa_corporal\",\"pedigri_diabetes\",\"edad\",\"diabetes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a31df78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- embarazo_meses: integer (nullable = true)\n",
      " |-- concentracion_glucosa: integer (nullable = true)\n",
      " |-- presion_arterial: integer (nullable = true)\n",
      " |-- espesor_triceps: integer (nullable = true)\n",
      " |-- insulina: integer (nullable = true)\n",
      " |-- masa_corporal: double (nullable = true)\n",
      " |-- pedigri_diabetes: double (nullable = true)\n",
      " |-- edad: integer (nullable = true)\n",
      " |-- diabetes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4c7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos nuestro Vector y Evaluador de precision del modelo\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8862c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"embarazo_meses\",\n",
    "                                       \"concentracion_glucosa\",\n",
    "                                       \"presion_arterial\",\n",
    "                                       \"espesor_triceps\",\n",
    "                                       \"insulina\",\n",
    "                                       \"masa_corporal\",\n",
    "                                       \"pedigri_diabetes\",\n",
    "                                       \"edad\"],\n",
    "                           outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e91369",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(data)\n",
    "output = output.select(['features','diabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15210061",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output.select(['features','diabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85505770",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d409e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "487bae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"diabetes\", featuresCol=\"features\", numTrees=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba236ee",
   "metadata": {},
   "source": [
    "## Numero de arboles\n",
    "\n",
    "El numero de arboles es determinado por la cantidad de datos a utilizar.\n",
    "La cantidad normal a utilizar es de 10 arboles, 30 arboles y 100 arboles.\n",
    "Tambien se encontro que cuando se tiene 1 lakh o mas, de datos, se maneja de 200 a 300 arboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8cfd9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2dbc5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|diabetes|prediction|\n",
      "+--------+----------+\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_data)\n",
    "predictions.select(\"diabetes\",\"prediction\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c1d969b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='diabetes', predictionCol='prediction',metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29e8cb",
   "metadata": {},
   "source": [
    "## Evaluamos\n",
    "Se evalua la precision de nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa9d107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.19841269841269837%\n",
      "Accuracy: 0.8015873015873016%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Error = {}%\".format(1.0-accuracy))\n",
    "print(\"Accuracy: {}%\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
